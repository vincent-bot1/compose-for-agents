services:

  agents:
    image: demo/agents
    build:
      context: agent
    ports:
      - "7777:7777"
    environment:
      - OPENAI_API_KEY=$OPENAI_API_KEY
      # point agents at the MCP gateway
      - MCPGATEWAY_ENDPOINT=http://mcp-gateway:8811/sse
    volumes:
      # mount the agents file
      - ./agents.yaml:/agents.yaml
    models:
      qwen3-small:
        endpoint_var: MODEL_RUNNER_URL
        model_var: MODEL_RUNNER_MODEL

  agents-ui:
    image: demo/ui
    build:
      context: agent-ui
    ports:
      - "3000:3000"
    environment:
      - AGENTS_URL=http://localhost:7777
    depends_on:
      - agents

  mcp-gateway:
    # mcp-gateway secures your MCP servers
    image: docker/mcp-gateway:latest
    # use docker API socket to start MCP servers
    use_api_socket: true
    command:
      # securely embed secrets into the gateway
      - --secrets=/run/secrets/mcp_secret
      # add any MCP servers you want to use
      - --servers=github-official
      # add an interceptor to format and simplify the output of the GitHub issues tool
      # this interceptor will convert the JSON output of the tool into a CSV format
      - --interceptor
      - after:exec:cat | jq '.content[0].text = (.content[0].text | fromjson | map(select(. != null) | [(.number // ""), (.state // ""), (.title // ""), (.user.login // ""), ((.labels // []) | map(.name) | join(";")), (.created_at // "")] | @csv) | join("\n"))'
    secrets:
      - mcp_secret

models:
  qwen3-small:
    # pre-pull the model when starting Docker Model Runner
    #model: ai/qwen3:30B-A3B-Q4_K_M
    model: ai/qwen3:8B-Q4_0 # 4.44 GB
    context_size: 15000 # 7 GB VRAM
    # increase context size to handle larger results
    # context_size: 41000 # 13 GB VRAM
  qwen3-medium:
    model: ai/qwen3:14B-Q6_K # 11.28 GB
    context_size: 15000 # 15 GB VRAM
    # increase context size to handle larger results
    # context_size: 41000 # 21 GB VRAM

  # The qwen3-large model is defined in compose.offload.yaml
  # because it requires more resources and is intended to run with Docker Offload.
  # A recommended practice with Docker Compose is to isolate specialized configurations
  # in override files. These files modify the base setup when applied,
  # in our case:
  # docker compose -f compose.yaml -f compose.offload.yaml up --build

# mount the secrets file for MCP servers
secrets:
  mcp_secret:
    file: ./.mcp.env
